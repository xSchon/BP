{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "376efb13-db27-4f71-a857-5b6b27e793a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "from feature_engine.creation import CyclicalTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.preprocessing import PowerTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cff9cb-83e1-4a28-94ef-3c1f1f392537",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/data_after_EDA.csv'\n",
    "START_DATE = '01/25/2019'\n",
    "END_DATE = '04/24/2022'\n",
    "\n",
    "# Display all of the columns when data are shown\n",
    "pd.set_option('display.max_columns', 60) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcd79fd-1157-4b75-8066-b10b6426d2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  pd.read_csv(DATA_PATH, sep=',', parse_dates=['doc_date'], low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00d3838-3c59-4073-b781-96efac281416",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94fd944-b855-46fe-915d-a24b80d5ced0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae650d7-b98f-46b5-b1f7-830c1af0e7cc",
   "metadata": {},
   "source": [
    "# 1. Change non-numeric values to numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4ef74c-f840-492f-8440-ac9d50d515fa",
   "metadata": {},
   "source": [
    "Machine learning models usually work only with numeric values (integers or floats) - that's why we need to change other formats to numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60372ff5-3de1-43e5-9521-451bac262abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2482dbdb-67a1-4415-a952-19f70dc50413",
   "metadata": {},
   "source": [
    "At first let's start with breaking down dates to four different columns - we can extract day of the month, day of the week, week, month and year. We will still keep the original datetime column in code, because it can be useful to easier access date (rather then creating it from columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788a5b7e-36e1-4376-b8a1-92768a888d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "years, months, days, weeks, weekdays = [], [], [], [], []\n",
    "for date in data['doc_date']:\n",
    "    years.append(date.year)\n",
    "    months.append(date.month)\n",
    "    days.append(date.day)\n",
    "    weekdays.append(date.weekday())\n",
    "    weeks.append(date.week)\n",
    "    \n",
    "    \n",
    "\n",
    "data['doc_day'] = days\n",
    "data['doc_month'] = months\n",
    "data['doc_year'] = years\n",
    "data['doc_weekday'] = weekdays\n",
    "data['doc_week'] = weeks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d282297-d151-4bc8-81ab-473e719df622",
   "metadata": {},
   "source": [
    "**The next part is to find columns that already have their natural number representation - i.e. product_name_parameterize is not necesarry column as we have product_id (numeric products identification)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fa8c41-98ad-4711-948a-77595fc8c580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename catalog_COLUMN to COLUMN only so it is easier to understand\n",
    "data.rename(columns={'catalog_category_id' : 'category_id', 'catalog_segment_id' : 'segment_id', 'catalog_brand_id' : 'brand_id'}, inplace=True)\n",
    "\n",
    "# rename other id columns with extra words to pure defining id in similar spirit as with catalog\n",
    "data.rename(columns={'setting_currency_id' : 'currency_id', 'shop_basket_id' : 'basket_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d84bd1-9b4f-4306-834d-9b6a8d4d2954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_only_id_column(df : pd.DataFrame(), id_column : str, other_columns : list, inplace : bool = False) -> pd.DataFrame():\n",
    "    \"\"\"\n",
    "    Function that counts and compares if product_id is proper representation of other given columns. If yes, then drop other columns and leave id only.\n",
    "    Args\n",
    "        df - pandas DataFrame containing desired columns\n",
    "        id_column - main column containing identificator, this column will be the only one remaining\n",
    "        other_columns - list of other columns, those will be compared and possibly dropped\n",
    "        inplace - If False, return a copy. Otherwise, do operation inplace and return None.\n",
    "    Returns\n",
    "        pd.DataFrame - DataFrame with removed columns in other_columns or None if inplace is True\n",
    "    \"\"\"\n",
    "    id_col_len = len(data[id_column].unique())\n",
    "    \n",
    "    unique_combinations = len(df[other_columns + [id_column]].drop_duplicates().index)\n",
    "    other_cols_string = ''\n",
    "    for name in other_columns:\n",
    "        other_cols_string += name+', '\n",
    "    \n",
    "    print(f\"{id_col_len} - Unique {id_column} amount.\")\n",
    "    print(f\"{unique_combinations} - Amount of unique combinations of {id_column} and {other_cols_string}\")\n",
    "    \n",
    "    missmatches_amount = abs(id_col_len - unique_combinations)\n",
    "    print(f\"{missmatches_amount} - How many missmatches between {id_column} and other columns.\")\n",
    "    \n",
    "    if missmatches_amount == 0:\n",
    "        if inplace:\n",
    "            df.drop(labels=other_columns, inplace=inplace, axis=1)\n",
    "            return None\n",
    "        else:\n",
    "            return df.drop(labels=other_columns, inplace=inplace, axis=1)\n",
    "        \n",
    "    else: \n",
    "        print('There were missmatches, not dropping any columns.')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c1c565-36ad-4a5d-a0ad-845b1afb3656",
   "metadata": {},
   "source": [
    "Because each product id represents one product correctly, we can drop product name as well as parameterized product name. \\\n",
    "We can drop product_code as well for the same reason - product id represents same products as product_code but in different encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302664c0-dca7-4959-bc0f-205a96c0ae4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "leave_only_id_column(data, 'product_id', ['product_name', 'product_code'], inplace=True)\n",
    "print('\\n')\n",
    "\n",
    "leave_only_id_column(data, 'product_id', ['product_name_parameterize'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38d7180-1ffd-4dfc-979f-c030895903e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[['product_id' , 'product_name_parameterize']].drop_duplicates().product_id.value_counts().head(10))\n",
    "data[data[['product_id' , 'product_name_parameterize', 'item_type']].product_id.__eq__(147573)][['product_name_parameterize']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec84735-b1a6-470d-af28-69a43033d200",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(labels='product_name_parameterize', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a25915-eddd-4401-8ddf-9f1fc9298939",
   "metadata": {},
   "source": [
    "Product name parameterize has 7 different than unique values. If we look deeper into it we can see that it is only because there is -set added to the end of the name parameterized. This is deprecated way of set selling, since there is now column (item_type) to differentiate between sets and standard items. That's why we can drop product_name_parametereize as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f647f3-6bec-4599-bdec-3a8d7eb94d8b",
   "metadata": {},
   "source": [
    "Similar to products, there is many alike records in data (columns represented by other column), we can take care of all of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fbbc4d-9262-4a33-a40f-5fe1a24f0599",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "leave_only_id_column(data, 'category_id', ['category', 'category_name_parameterized'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f309f03-7f5f-4cde-ac16-c88ddc440e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "leave_only_id_column(data, 'brand_id', ['brand_name', 'brand_parameterized'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d403fd-2e18-4d14-b633-3c39c098e08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "leave_only_id_column(data, 'currency_id', ['original_currency_code'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe12418-2510-4eed-a3fb-1dbb21b8daef",
   "metadata": {},
   "outputs": [],
   "source": [
    "leave_only_id_column(data, 'segment_id', ['segment_parameterized', 'segment_name'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2789fce-bbfb-4fc0-bc5c-0bfd3499d16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "leave_only_id_column(data, 'tree_path', ['category_full_name_path'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cb00b2-afa7-462b-915d-d30c98ee94e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In tree path we want to keep it separated in two columns for now - categorty_descendants (parents) and category_ancestors (subcategories). We will check for missmatches and drop tree_path if there are none\n",
    "leave_only_id_column(data, 'tree_path', ['categories_descendant_ids', 'categories_ancestor_ids'])\n",
    "\n",
    "data.drop(labels='tree_path', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb52695-292f-4baa-9a37-6cfd9b59a727",
   "metadata": {},
   "source": [
    "**Coding remaining string and boolean values to numerics** \\\n",
    "With the usage of replace (booleans) and OrdinalEncounter (strings) we will change values to their representation in numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743ea4a3-b258-4904-82bd-1af4bfc442ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace([True, False], [1, 0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4495ec4-fb59-413f-9252-8b92f3ee73da",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_change = ['bill_country',\n",
    " 'basket_type',\n",
    " 'item_type',\n",
    " 'product_status',\n",
    " 'category_status']\n",
    "\n",
    "ce_ordinal = ce.OrdinalEncoder(cols=columns_to_change)\n",
    "data = ce_ordinal.fit_transform(data)\n",
    "\n",
    "for mapped in ce_ordinal.fit(data).mapping:\n",
    "    print(f\"Column {mapped['col']} has mapping of:\")\n",
    "    print(f\"{mapped['mapping']} \\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec93fd85-d515-4559-a4ae-c60f3b7a4a15",
   "metadata": {},
   "source": [
    "Instead of saving full path to category we just want to know how deep given category is and how many subcategories it has. We will convert arrays of ancestors/ descendants into numbers representing amounts of ids in given lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eaece3-33ac-4622-a66c-f3dbee718f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "ancestor_count = [len(i.split(',')) for i in data.categories_ancestor_ids]\n",
    "descendant_count = [len(i.split(',')) for i in data.categories_descendant_ids]\n",
    "\n",
    "data['ancestor_count'] = ancestor_count\n",
    "data['descendant_count'] = descendant_count\n",
    "\n",
    "data.ancestor_count.value_counts(normalize=True).sort_index().plot(kind='barh', title='Ancestor count share')\n",
    "plt.show()\n",
    "\n",
    "data.descendant_count.value_counts(normalize=True).sort_index().plot(kind='barh', title='Descendant count share')\n",
    "plt.show()\n",
    "\n",
    "data.drop(labels=['categories_ancestor_ids', 'categories_descendant_ids'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bfc804-7d92-434d-b8de-8c9d65af4848",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bd625b-bb04-490b-9738-dec62d3871c4",
   "metadata": {},
   "source": [
    "# 2. Dealing with outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f18f7b5-8466-4ac0-a05e-0e19fac73377",
   "metadata": {},
   "source": [
    "In this part we want to delete outliers, as those might negatively influenece machine learning algorithm. That is why we want to delete at least the first iteration of outliers. There is ~5% values as outliers in the first iteration, which, we consider, is reasonable price to pay for cleaner and more useful data.\\\n",
    "We are considering values further than *3x standard deviations ($\\sigma$) from the mean ($\\mu$)* as outliers in our preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f776d46d-59ab-4372-ba81-08fceff13ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    " def delete_outliers(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function deletes rows containing outlier value in any of the columns and returns adjusted dataframe\n",
    "    Args\n",
    "        df - dataframe containing columns to check for outliers\n",
    "    Returns\n",
    "        DataFrame without outlier values\n",
    "    \"\"\"\n",
    "    for cols in df.columns:    \n",
    "        # Check for each column in the dataframe    \n",
    "        data_frame = df[cols]\n",
    "        data_mean, data_std = np.mean(data_frame), np.std(data_frame)  # Outlier > mean+3*std OR outlier < mean-3*std\n",
    "\n",
    "        # Outliers percentage definition\n",
    "        cut_off = data_std * 3\n",
    "        lower, upper = data_mean - cut_off, data_mean + cut_off \n",
    "\n",
    "        # Identify and remove outliers\n",
    "        outliers = [False if x < lower or x > upper else True for x in data_frame] \n",
    "            \n",
    "        # Information for the user about deleting rows based on given column\n",
    "        if outliers.count(False) > 0:\n",
    "            print(f'Identified outliers: {outliers.count(False)} in column: {cols}')\n",
    "        df = df[outliers]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f294382f-5484-45fc-a714-f071d8f90977",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_outliers_columns = ['basket_total_price_with_vat', \n",
    "                          'count_basket_items', \n",
    "                          'basket_count_products', \n",
    "                          'item_quantity', \n",
    "                          'item_unit_price_with_vat', \n",
    "                          'item_total_discount_with_vat', \n",
    "                          'reviews_count', \n",
    "                          'reviews_average_score_price', \n",
    "                          'reviews_average_score_quality', \n",
    "                          'reviews_average_score_properties', \n",
    "                          'reviews_average_score_overall',\n",
    "                          'reviews_average_score', \n",
    "                          'product_purchase_price',\n",
    "                          'eshop_stock_count', \n",
    "                          'ancestor_count', \n",
    "                          'descendant_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fb7f5e-9cc1-4367-a798-9b67f49d3970",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_outliers(data[['basket_total_price_with_vat']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8831f86d-1d8d-4f99-a0e0-988794f0ba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in check_outliers_columns:\n",
    "    data[col] = delete_outliers(data[[col]])\n",
    "    data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fceb2cf-e535-4625-bc54-ff051257f21c",
   "metadata": {},
   "source": [
    "# 3. Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffba27c9-5a56-45af-98cd-e9a17d4f89d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_columns = [''\n",
    "\n",
    "\n",
    "']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(data[scaled_columns])\n",
    "scaled = pd.DataFrame(scaled, columns = scaled_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4042eee-59ad-4ef9-9381-9557c7e36d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962db423-ba03-4d40-9e32-0ad9017e3953",
   "metadata": {},
   "outputs": [],
   "source": [
    "TODO_TRANSFORM = list(data.columns)\n",
    "TODO_TRANSFORM.remove('doc_day')\n",
    "TODO_TRANSFORM.remove('doc_week')\n",
    "TODO_TRANSFORM.remove('doc_year')\n",
    "TODO_TRANSFORM.remove('doc_weekday')\n",
    "TODO_TRANSFORM.remove('doc_month')\n",
    "TODO_TRANSFORM.remove('doc_date')\n",
    "TODO_TRANSFORM.remove('is_in_stock')\n",
    "TODO_TRANSFORM.remove('is_ended')\n",
    "TODO_TRANSFORM.remove('is_new')\n",
    "TODO_TRANSFORM.remove('is_fifo')\n",
    "TODO_TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfa3839-dd6d-4cc3-bc4b-03b1198a0422",
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclical = CyclicalTransformer(variables=['doc_day', 'doc_week', 'doc_weekday', 'doc_month'], drop_original=True)\n",
    "cyclical.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff58246-34cf-4d09-975d-f6872dabbcf6",
   "metadata": {},
   "source": [
    "# 4. Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e258ce19-ddce-4c5c-8161-cd93b35a4d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-MEANS CLUSTERING\n",
    "# Importing Modules\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c56ed3-7b23-4ec9-8ae1-ce21e52465c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68d953b-6bb4-47b1-b39d-9cfcd933d80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeansable = data[[\n",
    " 'item_type',\n",
    " 'product_id',\n",
    " 'category_id',\n",
    " 'brand_id',\n",
    " 'product_status',\n",
    " 'reviews_count',\n",
    " 'reviews_average_score_price',\n",
    " 'reviews_average_score_quality',\n",
    " 'reviews_average_score_properties',\n",
    " 'reviews_average_score_overall',\n",
    " 'reviews_average_score',\n",
    " 'is_in_stock',\n",
    " 'is_ended',\n",
    " 'is_new',\n",
    " 'product_purchase_price',\n",
    " 'eshop_stock_count',\n",
    " 'is_fifo',\n",
    " 'category_status',\n",
    " 'segment_id',\n",
    " 'default_warranty_period',\n",
    " 'ancestor_count',\n",
    " 'descendant_count']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da1c41c-9d3b-49cf-9b5f-acd123703f4e",
   "metadata": {},
   "source": [
    "At first we will use kMeans clustering, as agglomerative clustering can be done on large dataset easier than other types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d130775d-8190-4df0-8619-2ff012183505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring Model\n",
    "model = KMeans(n_clusters=101)\n",
    "\n",
    "# Fitting Model\n",
    "model.fit(kmeansable)\n",
    "\n",
    "# Prediction on the entire data\n",
    "all_predictions = model.predict(kmeansable)\n",
    "\n",
    "kmeansable['kmeans_cluster'] = all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17280c83-d286-4e0e-ab10-25f7a3ba6f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(all_predictions, return_counts = True)\n",
    "plt.bar(unique, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38be7d24-79cd-4db1-af1c-b75ddde61d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_tester = kmeansable[kmeansable.kmeans_cluster.__eq__(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059f3b65-7613-480d-a38e-b511c4478b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the fcluster and linkage functions\n",
    "from scipy.cluster.hierarchy import fcluster, linkage\n",
    " \n",
    "# Use the linkage() function\n",
    "distance_matrix = linkage(cluster_tester, method = 'ward', metric = 'euclidean')\n",
    "                                      \n",
    "tmp = fcluster(distance_matrix, 3, criterion='maxclust')\n",
    "\n",
    "unique, counts = np.unique(tmp, return_counts = True)\n",
    "plt.bar(unique, counts)\n",
    "plt.plot()\n",
    "cluster_tester['cluster_hierar'] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfec183-4e38-479e-abef-aa6f697d6d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_tester = cluster_tester[cluster_tester.cluster_hierar.__eq__(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dd6f55-ed5b-45a3-a56e-c544d0efa338",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = data[data.product_id.isin(cluster_tester.product_id.values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd530cc5-1051-45fa-8865-0e9c215a8608",
   "metadata": {},
   "source": [
    "# 5. Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97578df-1e86-4d8b-a182-b15c3b7df71b",
   "metadata": {},
   "source": [
    "#### Drop unsettable columns\n",
    "We want to predict, how many items of given type we will sell. That means - the predicted column will be 'item_quantity'. We don't know, how many items will be in basket, it's type etc. We only know values of columns we can influence (or which are already written) - for example price of the product, or it's brand. These columns were great for clustering products, as they can show some patterns in them, but for pure pretictions we are dropping those data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e1f23a-0aab-4124-af90-a1e4e5de29f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_zeroes(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    # Add days when there were no products sold\n",
    "    date_column = 'doc_date'\n",
    "    dates = pd.date_range(start=START_DATE, end=END_DATE)\n",
    "\n",
    "    sales = []\n",
    "    for date in dates:\n",
    "        # if there is existing number of sales for given day, otherwise we know there are no such occurances\n",
    "        if len(df[df[date_column] == date]['item_quantity']) > 0:\n",
    "            sales.append(df[df[date_column] == date]['item_quantity'].sum())\n",
    "        else:\n",
    "            sales.append(0)\n",
    "\n",
    "    full_sales = pd.DataFrame()        \n",
    "    full_sales['invoice_date'] = dates\n",
    "    full_sales['quantity_sold'] = sales\n",
    "    return full_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a076e6ed-1872-472e-8a7e-d7579b6b9ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_zeroes(test_predict[test_predict.product_id.__eq__(197899)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf6e31f-2e73-4355-8802-4d6abab8f97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(labels=['basket_id', 'basket_total_price_with_vat', 'basket_count_products', 'basket_type', 'count_basket_items'], axis=1, inplace=True)\n",
    "test_predict.drop(labels=['basket_id', 'basket_total_price_with_vat', 'basket_count_products', 'basket_type', 'count_basket_items'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9888b556-333d-49a2-8ae7-8a1b408c41aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from catboost import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6b6d14-57d7-4f30-999e-07dcc4aba31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6c21c7-b28d-42c1-bdc1-251e4c229def",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict = test_predict[9500:]\n",
    "test_predict = test_predict[:9500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aabd771-ad51-45f1-9eb6-295bb3ba521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(\n",
    "    iterations=1000, \n",
    "    learning_rate=0.02, \n",
    "    max_depth=10, \n",
    "    l2_leaf_reg=10, \n",
    "    loss_function='RMSE',\n",
    "    random_seed=1,\n",
    "    od_type='Iter',\n",
    "    od_wait=25,\n",
    "    verbose=100,\n",
    "    use_best_model=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565c858c-230f-402c-9b86-0e42ee19f2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separated_values.columns[1:] means all but the first column == quantity_sold\n",
    "model.fit(test_predict.drop(labels=['doc_date', 'item_quantity'], axis=1), test_predict['item_quantity'],\n",
    "              early_stopping_rounds=3000,\n",
    "              verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65459576-8b6c-4e35-9939-285f0390ca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = [model.predict(test_predict.drop(labels=['doc_date', 'item_quantity'], axis=1).iloc[i]) for i in range (len(test_predict.index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31674150-15b0-46c8-9662-247f25627cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = list(test_predict.item_quantity.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef45f7b-8600-4405-b9fb-5e56b33a2973",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f85af0-f70e-4e86-b828-703e899f4dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9953e48f-c66f-4719-ab2e-0b48a360fd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = [model.predict(train_predict.drop(labels=['doc_date', 'item_quantity'], axis=1).iloc[i]) for i in range (len(train_predict.index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3161e79a-62e2-414b-88d4-f09d2aebec3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_test = list(train_predict.item_quantity.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8674d577-b1ea-492c-88c9-758d9768efd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5fdc54-eb08-4afc-9c5b-d37e4b8ad9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(orig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1793d503-a0d2-4c49-bf67-8b8211b1cb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "1447 / 1450"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a0313a-77e9-4782-ba2c-d2219c50b713",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "test_predict.doc_date.value_counts().plot(xlabel='Date of sale', ylabel='Amount of orders', title = 'Amount of orders at any given day')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb73c625-ae21-4216-b3d2-4662bf5a7a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#indexed_predictions = pd.DataFrame()\n",
    "#indexed_predictions['quantity_sold'] = predict_sold_test\n",
    "#indexed_predictions.index = test.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0157d279-bdbe-4aa4-9154-f6e75749053d",
   "metadata": {},
   "source": [
    "# IDEAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4955c55c-d4fc-40ba-bdaa-d2332bf65a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO \n",
    "OPIS TRANSOFMEROV MinMax a Cyclical\n",
    "OPIS A UPRATANIE CLUSTERINGU\n",
    "\n",
    "\n",
    "TODO \n",
    "preorbit kolacove grafy na boxploty, bar\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa64d68f-bf4e-45fe-a989-4ba6261edb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "IDEAS\n",
    "PRIDAJ ROZBITIE NA TRENDY DO Samotneho vyhodnocovania\n",
    "NAPOCITANIE PREDAJOV PRODUKTOV ZA TYZDEN????\n",
    "\n",
    "\n",
    "NEDAVAJ PIE GRAFY DO PRACE!!!!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ef1784-684c-4033-9086-330fab0b3df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = data[['product_id', 'doc_week', 'doc_year', 'item_quantity']].groupby(by=['doc_year', 'doc_week', 'product_id'], as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4f2f9a-98b0-41eb-88da-7d1d444ff731",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['doc_week', 'doc_year']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc01d49-47de-4fc9-b2f2-1ab1ac95d70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (16, 8)\n",
    "plt.rcParams['figure.dpi'] = 80\n",
    "\n",
    "unique, counts = np.unique(tmp.product_id.value_counts().values, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7be356-92bf-4e59-9e00-e6e3fcbc50ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(unique, counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
